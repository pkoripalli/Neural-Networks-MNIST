# Neural Networks MNIST

### MLP

#### MLP with 2 hidden layers

 1. Applied MLP + ReLu + ADAM on 2 hidden layers (512, 128) for 100 epochs
 2. Applied MLP + ReLu + ADAM + Dropout(0.5) on 2 hidden layers (512, 128) for 100 epochs
 3. Applied MLP + ReLu + ADAM + Batch Normalization on 2 hidden layers (512, 128) for 100 epochs
 4. Applied MLP + ReLu + ADAM + Dropout + Batch Normalization on 2 hidden layers (512, 128) for 100 epochs
 
#### MLP with 3 hidden layers

 1. Applied MLP + ReLu + ADAM on 3 hidden layers (392, 196, 98) for 100 epochs
 2. Applied MLP + ReLu + ADAM + Dropout(0.5) on 3 hidden layers (392, 196, 98) for 100 epochs
 3. Applied MLP + ReLu + ADAM + Batch Normalization on 3 hidden layers (392, 196, 98) for 100 epochs
 4. Applied MLP + ReLu + ADAM + Dropout + Batch Normalization on 3 hidden layers (392, 196, 98) for 100 epochs

#### MLP with 5 hidden layers
 1. Applied MLP + ReLu + ADAM on 5 hidden layers (392, 196, 98, 49, 24) for 100 epochs
 2. Applied MLP + ReLu + ADAM + Dropout(0.5) on 5 hidden layers (392, 196, 98, 49, 24) for 100 epochs
 3. Applied MLP + ReLu + ADAM + Batch Normalization on 5 hidden layers (392, 196, 98, 49, 24) for 100 epochs
 4. Applied MLP + ReLu + ADAM + Dropout + Batch Normalization on 5 hidden layers (392, 196, 98, 49, 24) for 100 epochs
  
### CNN

 1. Applied Convolution Neural Network Model on 3 convolution layers with kernel size (3, 3) for 50 epochs
 2. Applied Convolution Neural Network Model on 5 convolution layers with kernel size (5, 5) for 50 epochs
 3. Applied Convolution Neural Network Model on 7 convolution layers with kernel size (2, 2) for 50 epochs
